{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 规则验证模块\n",
    "\n",
    "## 主要任务\n",
    "\n",
    "规则验证模块的主要任务，是将硬匹配和软匹配的结果进行二次打标来验证。因为规则的标注并非完全准确，原本需要人去验证，但是人力验证成本过高，因此使用模型来代替人进行验证。\n",
    "\n",
    "这个模块需要一些训练语料来训练模型，同时需要上一轮的软硬匹配结果来进行二次打标。\n",
    "\n",
    "## 具体流程\n",
    "\n",
    "1. 模型训练\n",
    "2. 模型评估\n",
    "3. 模型预测 / 句子打标\n",
    "4. 冲突检验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验数据准备\n",
    "\n",
    "将 sent_train 数据集中的句子和标签全部利用来训练模型\n",
    "\n",
    "利用 Word2vec 将句子变成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入实验数据\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/xuhaoshuai/GitHub/HumanIE_IPM/data/sent_train/brother.csv\")\n",
    "verify_data = pd.read_csv(\"/Users/xuhaoshuai/GitHub/HumanIE_IPM/data/sent_veri/brother.csv\")\n",
    "\n",
    "# 抽取句子部分\n",
    "train_sent_set = train_data['sent']\n",
    "verify_sent_set = verify_data['sent']\n",
    "\n",
    "# 将 DataFrame 变成列表\n",
    "def split_by_space(sentence_set):\n",
    "    sent_word_list = []\n",
    "    for sentence in sentence_set:\n",
    "        sent_word_list.append(sentence.split())\n",
    "    return sent_word_list\n",
    "\n",
    "# train_sent_word_list = []\n",
    "# for sent in train_sent_set.tolist():\n",
    "#     train_sent_word_list.append(sent.split())\n",
    "\n",
    "train_sent_word_list = split_by_space(train_sent_set)\n",
    "verify_sent_word_list = split_by_space(verify_sent_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 加载和调用 Word2vec，构造模型的训练向量\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"/Users/xuhaoshuai/GitHub/HumanIE_IPM/src/softmatch/word2vec.model\")\n",
    "\n",
    "def sent2vec(sent_word_list):\n",
    "    X = []\n",
    "    for sent_word in train_sent_word_list:\n",
    "        sent_vec = np.zeros(100)\n",
    "        word_vec_sum = np.zeros(100)\n",
    "        for word in sent_word:\n",
    "            word_vec_sum = word_vec_sum + model.wv[word]\n",
    "        sent_vec = word_vec_sum / len(sent_word)\n",
    "        X.append(sent_vec.tolist())\n",
    "    return X\n",
    "\n",
    "X_train = sent2vec(train_sent_word_list)\n",
    "X_verify = sent2vec(verify_sent_word_list)\n",
    "\n",
    "y_train = np.array(train_data['label'].tolist())\n",
    "y_verify = np.array(train_data['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7723502304147465\n"
     ]
    }
   ],
   "source": [
    "# 分割数据为训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# 模型评估\n",
    "hard_svm = svm.SVC()\n",
    "soft_svm = svm.SVC()\n",
    "hard_svm.fit(X_train, y_train)\n",
    "soft_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_hard = hard_svm.predict(X_verify)\n",
    "y_pred_soft = soft_svm.predict(X_verify)\n",
    "\n",
    "hard_f1 = f1_score(y_verify, y_pred_hard, average='binary')\n",
    "soft_f1 = f1_score(y_verify, y_pred_soft, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测\n",
    "pred_data = pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
